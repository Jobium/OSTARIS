{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Processing Notebook\n",
    "This template script contains all the code needed to import and process FTIR spectra, then save them in a standardised file format. It can import and process a single file, or multiple files at once. Available processing includes:\n",
    "- Averaging for multi-spec measurements\n",
    "- Baseline (background) subtraction\n",
    "- Reference spectrum subtraction\n",
    "- Automatic peak detection\n",
    "- Automatic peak fitting\n",
    "\n",
    "# Requires input data files to be organised as follows:\n",
    "- Location: {Data_dir}/{Sample}/\n",
    "- Sample/Measurement metadata must be recorded in either file {spec filename}_MetaData.csv, or within spec filename\n",
    "    - Spec filename format:\n",
    "    \n",
    "        {Spec ID number}_{Sample}_{Subsample}_{notes}.txt\n",
    "    \n",
    "    - Each spectrum file in a given project must have a unique identifier (preferable a sequential ID number) so that it can always be distinguished from other measurements, even when they are otherwise identical. These ID numbers can be used to refer to particular spectra when manually specifying settings to use for outliers/exceptional cases.\n",
    "    - any pre-processing steps applied to the data should be included at the end of the filename\n",
    "        - C: cosmic ray removal\n",
    "        - O: outlier removal\n",
    "        - N: normalisation\n",
    "        \n",
    "# How to use this script:\n",
    "- Pick your directories and specify what sample/setting filters you want to apply when importing files\n",
    "- Adjust the data import string to make sure it matches your file structure and naming conventions (if necessary)\n",
    "- Each section of code starts with a set of user input variables to control what it does:\n",
    "\n",
    "             skip: skip this section entirely (True/False)\n",
    "            debug: print debug messages during execution (True/False)\n",
    "        show_plot: show plotted figures in viewer (True/False)\n",
    "        save_plot: save plotted figures to file (True/False)\n",
    "        \n",
    "    Data processing sections also need to be told what x,y values and keynames to use for input/output:\n",
    "    \n",
    "            x_key: the keyname to use as x values (e.g. 'raman_shift')\n",
    "            y_key: the keyname to use as y values (e.g. 'y_av_sub')\n",
    "          alt_key: the back-up keyname to use as y values if y_key does not exist for a given measurement (e.g. 'y_av')\n",
    "          new_key: the keyname to save the output under (e.g. 'y_av_refsub' or 'fitted_peaks')\n",
    "          \n",
    "    Some processing steps also have manual overrides, for example if you want to specify what measurements need to have a reference spectrum subtracted, or which peak positions to fit for a given measurement. Please refer to those sections.\n",
    "\n",
    "- To turn off/on sections of code, e.g. peak detection, simply use the 'skip' variable at the start of each section.\n",
    "- When rerunning sections of code, bear in mind that data and variables will reflect the most recent state and may give you unexpected results - sometimes it's safer to rerun the whole script. \n",
    "- When you are happy with the output of a particular section, you can switch the 'debug' variable to False to hide debug text generated in the window. It will continue to show key information, and plots.\n",
    "- To save time and memory, you can switch 'show_plot' to False to stop plots being rendered in the viewer. They will still be saved to disk if 'save_plot' is True.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================================================\n",
    "# define where your data is, and what files to import\n",
    "\n",
    "# list directories for input data, figures and output files\n",
    "Data_dir = '../FTIR data/'\n",
    "Fig_dir = '../FTIR figures/'\n",
    "Out_dir = '../FTIR output/'\n",
    "Ref_dir = '../FTIR data/References/'\n",
    "\n",
    "Technique = 'FTIR'         # 'Raman' or 'FTIR'\n",
    "\n",
    "# filter data import by sample / subsample\n",
    "Sample = '*'                # name of sample, or '*' for all\n",
    "Subsample = '*'             # name of subsample, or '*'\n",
    "Measurement_ID = '*'        # unique ID of measurement, or '*'\n",
    "\n",
    "# list spectral IDs to skip when importing data, as strings\n",
    "Do_Not_Import = ['012-JRH']\n",
    "\n",
    "# Import data by sample or spectrum?\n",
    "# - 'sample':   imports all spectra with the same sample name at the same time, referenced by sample name\n",
    "# - 'spectrum': imports spectra individually, referenced by spectrum ID\n",
    "Import_By = 'spectrum'\n",
    "\n",
    "# filter by measurement settings\n",
    "Metadata_File = False       # set to True to import metadata file, or False to extract data from spec filename\n",
    "Measurement_Date = '*'      # Date in YYYY-MM-DD format as string, or '*'\n",
    "Preprocessing = '*'         # specify required preprocessing, or '*' for best available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (OSTARIS_functions.py, line 19)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[0;36m(most recent call last)\u001b[0m:\n",
      "  File \u001b[1;32m\"/Users/joby/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\"\u001b[0m, line \u001b[1;32m2910\u001b[0m, in \u001b[1;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-2-68e585bd83c3>\"\u001b[0;36m, line \u001b[0;32m19\u001b[0;36m, in \u001b[0;35m<module>\u001b[0;36m\u001b[0m\n\u001b[0;31m    from OSTARIS_functions import *\u001b[0m\n",
      "\u001b[0;36m  File \u001b[0;32m\"/Users/joby/Dropbox/NHM Dropbox/OSTARIS/v02 scripts/OSTARIS_functions.py\"\u001b[0;36m, line \u001b[0;32m19\u001b[0m\n\u001b[0;31m    from scikit-learn.decomposition import PCA\u001b[0m\n\u001b[0m               ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# ==================================================\n",
    "# this section imports necessary python modules\n",
    "\n",
    "import os\n",
    "import math\n",
    "import glob\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lmfit as lmfit\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.optimize import curve_fit\n",
    "from scipy.signal import argrelextrema\n",
    "from scipy.signal import savgol_filter\n",
    "\n",
    "# import VibSpec module functions\n",
    "from OSTRI_functions import *\n",
    "\n",
    "\"\"\"\n",
    "# ==================================================\n",
    "# FILE SEARCH\n",
    "# - this section searches for spectrum files that match the specified settings\n",
    "# ==================================================\n",
    "\"\"\"\n",
    "\n",
    "print(\"SEARCHING FOR SPECTRUM DATA FILES...\")\n",
    "\n",
    "# find files\n",
    "#   - currently requires data files to be named and organised as follows:\n",
    "# Data_dir/{Sample}/{Measurement_ID}_{Sample}_{Subsample}_{Measurement Parameters}.txt\n",
    "text = \"%s%s/%s_%s_%s_%s_%s*CSV\" % (Data_dir, Measurement_Date, Measurement_ID,\n",
    "        Polymer, Environment, Timepoint, Sample)\n",
    "print(text)\n",
    "spec_dirs = sorted(glob.glob(text))\n",
    "\n",
    "if Import_By.lower() == 'sample':\n",
    "    # importing by sample name\n",
    "    \n",
    "    Sample_Names = np.unique([spec.split(\"/\")[-1].split(\"_\")[2] for spec in spec_dirs])\n",
    "    print()\n",
    "    print(\"Sample names found:\", Sample_Names)\n",
    "    \n",
    "    # find all unique measurement IDs for each sample\n",
    "    spec_dirs = []\n",
    "    for name in Sample_Names:\n",
    "        text = \"%s%s/*.CSV\" % (Data_dir, name)\n",
    "        temp = sorted(glob.glob(text))\n",
    "        Spec_IDs = np.unique([spec.split(\"/\")[-1].split(\"_\")[0] for spec in temp])\n",
    "        for ID in Spec_IDs:\n",
    "            # find appropriate pre-processed file for this measurement\n",
    "            spec_dirs.append([])\n",
    "            if Preprocessing != '*':\n",
    "                # use specified preprocessing\n",
    "                text = \"%s%s/*_%s.CSV\" % (Data_dir, name, ID, Preprocessing)\n",
    "                temp = sorted(glob.glob(text))\n",
    "                if len(temp) > 0:\n",
    "                    lengths = [len(s) for s in temp]\n",
    "                    spec_dirs[-1].append(temp[np.argmax(lengths)])\n",
    "            else:\n",
    "                # use best available\n",
    "                text = \"%s%s/%s_*.CSV\" % (Data_dir, Sample, ID)\n",
    "                temp = sorted(glob.glob(text))\n",
    "                if len(temp) > 0:\n",
    "                    lengths = [len(s) for s in temp]\n",
    "                    spec_dirs[-1].append(temp[np.argmax(lengths)])\n",
    "    \n",
    "else:\n",
    "    # importing by spectrum ID\n",
    "    \n",
    "    Spec_IDs = np.unique([spec.split(\"/\")[-1].split(\"_\")[0] for spec in spec_dirs])\n",
    "    print()\n",
    "    print(\"spectrum IDs found:\", Spec_IDs)\n",
    "\n",
    "    # find appropriate pre-processed file for each measurement\n",
    "    spec_dirs = []\n",
    "    for ID in Spec_IDs:\n",
    "        if Preprocessing != '*':\n",
    "            # use specified preprocessing\n",
    "            text = \"%s%s/%s_*_%s.CSV\" % (Data_dir, Sample, ID, Preprocessing)\n",
    "            temp = sorted(glob.glob(text))\n",
    "            if len(temp) > 0:\n",
    "                lengths = [len(s) for s in temp]\n",
    "                spec_dirs.append(temp[np.argmax(lengths)])\n",
    "        else:\n",
    "            # use best available\n",
    "            text = \"%s%s/%s_*.CSV\" % (Data_dir, Sample, ID)\n",
    "            temp = sorted(glob.glob(text))\n",
    "            if len(temp) > 0:\n",
    "                lengths = [len(s) for s in temp]\n",
    "                spec_dirs.append(temp[np.argmax(lengths)])\n",
    "\n",
    "print()\n",
    "print(\"data files found:\", len(spec_dirs))\n",
    "for file in spec_dirs:\n",
    "    print(\"    \", file.split(\"/\")[-1])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data import\n",
    "\n",
    "- this section actually imports data files and extracts their metadata\n",
    "- metadata can be in a separate CSV file with the same name plus '\\_metadata', or can be extracted from the data file's name\n",
    "- measurements are imported file by file, and added sequentially to the 'data' dict\n",
    "- to access a specific measurement, you call data\\[measurement ID\\]\\[key\\], where 'key' is the type of data you want from it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"IMPORTING DATA...\")\n",
    "\n",
    "# print debug messages?\n",
    "debug = True\n",
    "\n",
    "# set up data storage dictionary\n",
    "data = {}\n",
    "\n",
    "# ==================================================\n",
    "# each measurement imported will be added to this dictionary as a Measurement object\n",
    "# To access a particular measurement, use data[measurement ID]\n",
    "\n",
    "# for each detected file\n",
    "for spec_dir in spec_dirs:\n",
    "    while True:\n",
    "        try:\n",
    "            filename = spec_dir.split(\"/\")[-1][:-4]\n",
    "            ID = filename.split(\"_\")[0]\n",
    "            notes = ''\n",
    "            if ID in Do_Not_Import:\n",
    "                print()\n",
    "                print(\" measurement %s is in Do_Not_Import list, skipping\" % filename)\n",
    "                break\n",
    "            else:\n",
    "                print()\n",
    "                print(\"importing %s\" % filename)\n",
    "                # extract sample/measurement metadata\n",
    "                metadata = False\n",
    "                if Metadata_File == True:\n",
    "                    # search for metadata file with matching name\n",
    "                    metadata_dir = glob.glob(\"%s_Metadata.csv\" % spec_dir[:-4])\n",
    "                    print(\"    metadata files found:\", len(metadata_dir))\n",
    "                    if len(metadata_dir) > 0:\n",
    "                        metadata = True\n",
    "                if metadata == True:\n",
    "                    # get metadata from metadata file\n",
    "                    metadata = pd.read_csv(metadata_dir)\n",
    "                else:\n",
    "                    # get metadata from filename instead\n",
    "                    filename_split = filename.split(\"_\")\n",
    "                    # get sample info\n",
    "                    ID, date, sample, subsample = filename_split[:4]\n",
    "                    date = datetime.datetime.strptime(date, \"%Y-%m-%d\")\n",
    "                    # check for other info\n",
    "                    notes = ''\n",
    "                    if len(filename_split) >= 6:\n",
    "                        notes = filename_split[5]\n",
    "                \n",
    "                # report metadata\n",
    "                if debug == True:\n",
    "                    print(\"      measurement ID:\", ID)\n",
    "                    print(\"              sample:\", sample)\n",
    "                    print(\"           subsample:\", subsample)\n",
    "                    print(\"         measured on:\", date.strftime(\"%Y-%m-%d\"))\n",
    "                    print(\"               notes:\", notes)\n",
    "                    print(\"    measurement settings:\")\n",
    "                    print(\"                mode: FTIR\")\n",
    "                # import spectrum file (assumes CSV file formatting with 2 columns for x,y)\n",
    "                spec = np.genfromtxt(spec_dir, delimiter=',').transpose()\n",
    "                if debug == True:\n",
    "                    print(\"    spec array:\", np.shape(spec))\n",
    "                # single point, columns=(raman_shift, intensity)\n",
    "                spec_type = 'point'\n",
    "                points = 1\n",
    "                xy_coords = np.asarray([[0],[0]])\n",
    "                print(\"        single point measurement\")\n",
    "                x = spec[0]\n",
    "                y = spec[1:]\n",
    "                sort = np.argsort(x)\n",
    "                x = x[sort]\n",
    "                y = y.transpose()[sort,:]\n",
    "                \n",
    "                # check if transmittance or absorbance\n",
    "                if np.mean(y) > 10:\n",
    "                    mode = 'T'\n",
    "                    ylabel = 'Transmittance (%)'\n",
    "                else:\n",
    "                    mode = 'A'\n",
    "                    ylabel = 'Absorbance (arb. u.)'\n",
    "                \n",
    "                # trim infinities from both\n",
    "                check = np.logical_and(np.isinf(y) == False, np.isnan(y) == False)\n",
    "                if mode == 'T':\n",
    "                    # also trim 0's from transmittance (to ensure safe calculation of absorbance)\n",
    "                    check = np.logical_and(check, y != 0)\n",
    "                check = np.all(check, axis=1)\n",
    "                \n",
    "                print(\"               mode:\", ylabel)\n",
    "                if debug == True:\n",
    "                    print(\"            x array:\", np.shape(x))\n",
    "                    print(\"            x range: %0.f - %0.f cm-1\" % (np.amin(x), np.amax(x)))\n",
    "                    print(\"            y array:\", np.shape(y))\n",
    "                    print(\"            y range: %0.2f - %0.2f\" % (np.amin(y), np.amax(y)))\n",
    "                    print(\"          inf check:\", np.any(np.isinf(y)))\n",
    "                    print(\"          nan check:\", np.any(np.isnan(y)))\n",
    "                # generate sample title for consistent naming\n",
    "                title = \"%s_%s_%s\" % (ID, sample, subsample)\n",
    "                if notes != '':\n",
    "                    title += \"_\" + notes\n",
    "                # create Measurement instance from imported data\n",
    "                data[str(ID)] = Measurement(\n",
    "                    ID=str(ID),\n",
    "                    title=title,\n",
    "                    filename=filename,\n",
    "                    sample=sample,\n",
    "                    subsample=subsample,\n",
    "                    notes=notes,\n",
    "                    x=x[check],\n",
    "                    y=y[check,:],\n",
    "                    ykey=mode,\n",
    "                    ylabel=ylabel,\n",
    "                    technique='FTIR',\n",
    "                    generate_average=False,\n",
    "                    spec_type=spec_type,\n",
    "                    points=points,\n",
    "                    Fig_dir=Fig_dir,\n",
    "                    Out_dir=Out_dir,\n",
    "                    output_folder=''\n",
    "                )\n",
    "                if mode == 'T':\n",
    "                    # add absorbance spectrum\n",
    "                    data[str(ID)].add_spectrum(\n",
    "                        'A',\n",
    "                        transmittance2absorbance(y[check,:]),\n",
    "                        label=\"Absorbance (arb. u.)\"\n",
    "                    )\n",
    "                else:\n",
    "                    # add transmittance spectrum\n",
    "                    data[str(ID)].add_spectrum(\n",
    "                        'T',\n",
    "                        absorbance2transmittance(y[check,:]),\n",
    "                        label=\"Transmittance (%)\"\n",
    "                    )\n",
    "                \n",
    "                print(\"    imported successfully!\")\n",
    "                break\n",
    "        except Exception as e:\n",
    "            print(\"    something went wrong! Exception:\", e)\n",
    "            break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "debug = False\n",
    "\n",
    "# report which files were imported and which were not\n",
    "print()\n",
    "print(\"%s/%s files imported\" % (len(data.keys()), len(spec_dirs)))\n",
    "for num in Spec_IDs:\n",
    "    if num in data.keys():\n",
    "        print(\"    \", num, u'\\u2713', data[num]['filename'])\n",
    "    else:\n",
    "        text = ''\n",
    "        if num in Do_Not_Import:\n",
    "            text = 'ID in Do_Not_Import list'\n",
    "        print(\"    \", num, 'X', text)\n",
    "\n",
    "# update list of Spec IDs to only include imported spectra\n",
    "Spec_IDs = list(data.keys())\n",
    "\n",
    "samples = np.unique([data[num]['sample'] for num in Spec_IDs])\n",
    "print()\n",
    "print(\"samples in dataset:\")\n",
    "for sample in samples:\n",
    "    print(\"    \", sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot Results by Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# skip this section?\n",
    "skip = False\n",
    "\n",
    "# set whether to print debug messages in this section\n",
    "debug = True\n",
    "\n",
    "# keyname for x values to plot ('raman_shift', 'wavelength', 'frequency')\n",
    "x_key = 'frequency'\n",
    "\n",
    "# keyname for y values to plot\n",
    "y_key = 'A'\n",
    "\n",
    "# label for X axis\n",
    "x_label = \"Frequency (cm$^{-1}$)\"\n",
    "\n",
    "# label for Y axis\n",
    "y_label = 'Absorbance'\n",
    "\n",
    "# X range for plotting\n",
    "x_start, x_end = (400, 4000)\n",
    "\n",
    "# normalise data before plotting?\n",
    "normalise = True\n",
    "\n",
    "# offset spectra by this much (0 for no offset)\n",
    "offset = 0.\n",
    "\n",
    "# plot average spectrum as well?\n",
    "plot_average = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if skip == True:\n",
    "    print(\"SKIPPING SAMPLE SUMMARIES\")\n",
    "else:\n",
    "    print(\"PLOTTING SAMPLE SUMMARIES\")\n",
    "\n",
    "# plot sample spectra\n",
    "for sample in samples:\n",
    "    # get list of spec IDs for this sample\n",
    "    result = [ID for ID, measurement in data.items() if measurement.sample == sample]\n",
    "    spec_count = len(result)\n",
    "    print()\n",
    "    print(\"%s spectra:\" % sample, result)\n",
    "    \n",
    "    if offset != 0:\n",
    "        plt.figure(figsize=(8,2+len(result)))\n",
    "    else:\n",
    "        plt.figure(figsize=(8,4))\n",
    "    plt.title(\"Sample Spectra\\n%s\" % sample)\n",
    "    plt.xlabel(x_label)\n",
    "    plt.xlim(x_start, x_end)\n",
    "    if offset > 0:\n",
    "        plt.ylabel(y_label)\n",
    "        plt.yticks([])\n",
    "    else:\n",
    "        plt.ylabel(y_label)\n",
    "    \n",
    "    # plot average spectra\n",
    "    count = 0\n",
    "    if spec_count > 1:\n",
    "        x, y = average_spectra([data[ID] for ID in result], x_key, y_key, start=x_start, end=x_end,\n",
    "                              normalise=normalise, debug=debug)\n",
    "        plt.plot(x, y - count*offset, 'k', label='mean', zorder=3)\n",
    "    \n",
    "    # plot individual spectra\n",
    "    for ID in result:\n",
    "        x, y = get_plot_data(data[ID], x_key, y_key, start=x_start, end=x_end,\n",
    "                normalise=normalise, debug=debug)\n",
    "        plt.plot(x, y - count*offset, Colour_List[count % len(Colour_List)], label=\"%s\" % (ID))\n",
    "        count += 1\n",
    "        \n",
    "    plt.legend(loc=1)\n",
    "    plt.minorticks_on()\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Peak Detection\n",
    "- searches for local maxima that meet two thresholds:\n",
    "    1) relative intensity (vs maximum)\n",
    "    2) signal:noise ratio\n",
    "- produces figure showing which maxima passed and failed\n",
    "- also shows any manually specified maxima from Manual_Peaks[spec ID]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# skip this section?\n",
    "skip = False\n",
    "\n",
    "# print debug messages in viewer?\n",
    "debug = True\n",
    "\n",
    "# minimum signal:noise ratio threshold\n",
    "SNR_threshold=10\n",
    "\n",
    "# minimum intensity threshold relative to max\n",
    "norm_threshold=0.25\n",
    "\n",
    "# minimum peak-peak separation\n",
    "min_sep=20\n",
    "\n",
    "# keyname of x value parameter to use ('raman_shift', 'wavelength', 'frequency')\n",
    "x_key = 'frequency'\n",
    "\n",
    "# keyname of y value parameter to use\n",
    "y_key = 'A'\n",
    "\n",
    "# back-up keyname if y_key does not exist\n",
    "alt_key = 'A'\n",
    "\n",
    "# keyname for detected peak table\n",
    "new_key ='detected-peaks'\n",
    "\n",
    "# show plot in viewer?\n",
    "show_plot = True\n",
    "\n",
    "# save plots to file?\n",
    "save_plot = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if skip == True:\n",
    "    print(\"SKIPPING AUTOMATIC PEAK DETECTION\")\n",
    "else:\n",
    "    print(\"DOING AUTOMATIC PEAK DETECTION\")\n",
    "    \n",
    "    \n",
    "    process_count = 1\n",
    "    for ID, measurement in data.items():\n",
    "        print()\n",
    "        print(\"%s/%s detecting peaks for %s\" % (process_count, len(data.keys()), measurement.title))\n",
    "\n",
    "        if hasattr(measurement, y_key) == True:\n",
    "            key = y_key\n",
    "        else:\n",
    "            key = alt_key\n",
    "\n",
    "        detect_peaks(measurement, x_key, key, new_key, SNR_threshold=SNR_threshold,\n",
    "                     norm_threshold=norm_threshold, min_sep=min_sep, show_plot=show_plot, save_plot=save_plot,\n",
    "                     debug=debug)\n",
    "        process_count += 1\n",
    "        print(\"    done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare Samples with the same label\n",
    "- this section groups spectra according to a specified property and plots comparison figures for each group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# skip this section?\n",
    "skip = False\n",
    "\n",
    "# set whether to print debug messages in this section\n",
    "debug = False\n",
    "\n",
    "# keyname for x values to plot ('raman_shift', 'wavelength', 'frequency')\n",
    "x_key = 'frequency'\n",
    "\n",
    "# keyname for y values to plot\n",
    "y_key = 'A'\n",
    "\n",
    "# label for X axis\n",
    "x_label = \"Frequency (cm$^{-1}$)\"\n",
    "\n",
    "# label for Y axis\n",
    "y_label = 'Normalised Intensity'\n",
    "\n",
    "# X range for plotting\n",
    "x_start, x_end = (800, 1800)\n",
    "\n",
    "# normalise data before plotting?\n",
    "normalise = True\n",
    "\n",
    "# offset spectra by this much (0 for no offset)\n",
    "offset = 0.\n",
    "\n",
    "# group spectra by this parameter\n",
    "grouping = 'notes'\n",
    "\n",
    "# plot average spectra?\n",
    "plot_average = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if skip == True:\n",
    "    print(\"SKIPPING SAMPLE COMPARISON\")\n",
    "else:\n",
    "    print(\"PLOTTING SAMPLE COMPARISONS\")\n",
    "\n",
    "    # get groupings\n",
    "    groups = list(np.unique([measurement[grouping] for ID, measurement in data.items() if hasattr(measurement, grouping)]))\n",
    "    print()\n",
    "    print(\"%s groups found:\" % len(groups), groups)\n",
    "    \n",
    "    # plot spectra for each group separately\n",
    "    for group in groups:\n",
    "        result = [ID for ID, measurement in data.items() if getattr(measurement, grouping, \"\") == group]\n",
    "        spec_count = len(result)\n",
    "        print()\n",
    "        print(\"plotting group %s, %s spectra found\" % (group, spec_count))\n",
    "        if debug == True:\n",
    "            print(\"    \", result)\n",
    "        \n",
    "        count = 0\n",
    "\n",
    "        if offset != 0:\n",
    "            plt.figure(figsize=(8,2+len(result)))\n",
    "        else:\n",
    "            plt.figure(figsize=(8,4))\n",
    "        plt.title(\"Sample Spectra\\n%s\" % group)\n",
    "        plt.xlabel(x_label)\n",
    "        plt.xlim(x_start, x_end)\n",
    "        if offset > 0:\n",
    "            plt.ylabel(y_label)\n",
    "            plt.yticks([])\n",
    "        else:\n",
    "            plt.ylabel(y_label)\n",
    "\n",
    "        # plot average spectra\n",
    "        count = 0\n",
    "        if plot_average == True and spec_count > 1:\n",
    "            x, y = average_spectra([data[ID] for ID in result], x_key, y_key, start=x_start, end=x_end,\n",
    "                                  normalise=normalise, debug=debug)\n",
    "            plt.plot(x, y - count*offset, 'k', label='mean', zorder=3)\n",
    "\n",
    "        # plot individual spectra\n",
    "        for ID in result:\n",
    "            # check which key to use\n",
    "            if hasattr(measurement, y_key) == True:\n",
    "                key = y_key\n",
    "            else:\n",
    "                key = alt_key\n",
    "            \n",
    "            # get data\n",
    "            x, y = get_plot_data(data[ID], x_key, key, start=x_start, end=x_end,\n",
    "                    normalise=normalise, debug=debug)\n",
    "            \n",
    "            # plot spectra\n",
    "            if len(result) < 10:\n",
    "                # plot individual spectra as distinct lines with their own labels\n",
    "                plt.plot(x, y - count*offset, Colour_List[count % len(Colour_List)],\n",
    "                         alpha=1./np.sqrt(spec_count), label=\"%s\" % (ID))\n",
    "            else:\n",
    "                # too many spectra to label individually, plot all spectra as semi-transparent lines of the same colour\n",
    "                plt.plot(x, y - count*offset, Colour_List[groups.index(group) % len(Colour_List)],\n",
    "                         alpha=1./np.sqrt(spec_count))\n",
    "            count += 1\n",
    "            \n",
    "        plt.legend(loc=1)\n",
    "        plt.minorticks_on()\n",
    "        plt.tight_layout()\n",
    "        if save_plot == True:\n",
    "            plt.savefig(\"%s%s-spectra.png\" % (Fig_dir, group), dpi=300)\n",
    "        if show_plot == True:\n",
    "            plt.show()\n",
    "        else:\n",
    "            plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare Samples with different labels\n",
    "- this section groups spectra according to a specified property and plots comparison figures for group averages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# skip this section?\n",
    "skip = False\n",
    "\n",
    "# set whether to print debug messages in this section\n",
    "debug = False\n",
    "\n",
    "# keyname for x values to plot ('raman_shift', 'wavelength', 'frequency')\n",
    "x_key = 'frequency'\n",
    "\n",
    "# keyname for y values to plot\n",
    "y_key = 'A'\n",
    "\n",
    "# label for X axis\n",
    "x_label = \"Frequency (cm$^{-1}$)\"\n",
    "\n",
    "# label for Y axis\n",
    "y_label = 'Normalised Intensity'\n",
    "\n",
    "# X range for plotting\n",
    "x_start, x_end = (800, 1800)\n",
    "\n",
    "# normalise data before plotting?\n",
    "normalise = True\n",
    "\n",
    "# offset spectra by this much (0 for no offset)\n",
    "offset = 0.\n",
    "\n",
    "# group spectra by this parameter\n",
    "grouping = 'notes'\n",
    "\n",
    "# plot average spectra?\n",
    "plot_average = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if skip == True:\n",
    "    print(\"SKIPPING SAMPLE COMPARISON\")\n",
    "else:\n",
    "    print(\"PLOTTING SAMPLE COMPARISONS\")\n",
    "\n",
    "    # get groupings\n",
    "    groups = list(np.unique([measurement[grouping] for ID, measurement in data.items() if hasattr(measurement, grouping)]))\n",
    "    print()\n",
    "    print(\"%s groups found:\" % len(groups), groups)\n",
    "        \n",
    "    if offset != 0:\n",
    "        plt.figure(figsize=(8,2+len(groups)))\n",
    "    else:\n",
    "        plt.figure(figsize=(8,4))\n",
    "    plt.title(\"Average Spectra\\nGrouped by %s\" % grouping)\n",
    "    plt.xlabel(x_label)\n",
    "    plt.xlim(x_start, x_end)\n",
    "    if offset != 0:\n",
    "        plt.ylabel(y_label)\n",
    "        plt.yticks([])\n",
    "    else:\n",
    "        plt.ylabel(y_label)\n",
    "        \n",
    "    count = 0\n",
    "\n",
    "    # plot spectra for each group separately\n",
    "    for group in groups:\n",
    "        result = [ID for ID, measurement in data.items() if getattr(measurement, grouping, \"\") == group]\n",
    "        spec_count = len(result)\n",
    "        \n",
    "        x, y = average_spectra([data[ID] for ID in result], x_key, y_key, start=x_start, end=x_end,\n",
    "                    normalise=normalise, debug=debug)\n",
    "        plt.plot(x, y - count*offset, Colour_List[count % len(Colour_List)], label=group, zorder=3)\n",
    "        count += 1\n",
    "\n",
    "    plt.legend(loc=1)\n",
    "    plt.minorticks_on()\n",
    "    plt.tight_layout()\n",
    "    if save_plot == True:\n",
    "        plt.savefig(\"%s%s_av-spectra.png\" % (Fig_dir, grouping), dpi=300)\n",
    "    if show_plot == True:\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Processed Spectra\n",
    "- for all measurements, the average spectrum is saved to _av-spectrum.csv\n",
    "    - includes columns for raw intensity, baselined intensity, and normalised values\n",
    "- for multi-spec measurements (e.g. maps and line-scans), all point-spectra are saved to _all-spectra_baselined.csv\n",
    "    - each spectrum is saved as a column along with its X,Y coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# skip this section?\n",
    "skip = False\n",
    "\n",
    "# set whether to print debug messages in this section\n",
    "debug = False\n",
    "\n",
    "# set whether to output metadata files\n",
    "Save_metadata = True\n",
    "\n",
    "if skip == True:\n",
    "    print(\"SKIPPING FILE OUTPUT\")\n",
    "else:\n",
    "    print(\"SAVING PROCESSED SPECTRA TO OUTPUT FOLDER\")\n",
    "    \n",
    "    for ID, measurement in data.items():\n",
    "        title = measurement.title\n",
    "        print()\n",
    "        print(title)\n",
    "\n",
    "        # one column for each modification of spectrum\n",
    "        headers = ['Wavelength (nm)', 'Frequency (cm-1)', 'Transmittance (%)', 'Absorbance (Arb. Units)']\n",
    "        keys = ['wavelength', 'frequency', 'T', 'A']\n",
    "        save_measurement(measurement, keys=keys, headers=headers, save_name='av-spectrum', debug=debug)\n",
    "\n",
    "        # save all point-spectra to file (maps & multi-spec files only)\n",
    "        if measurement.points > 1 and hasattr(measurement, 'y'):\n",
    "            # one column per baselined point-spectrum\n",
    "            headers = ['Wavelength (nm)', 'Frequency', 'Absorbance (Arb. Units)']\n",
    "            keys = ['wavelength', 'frequency', 'A']\n",
    "            save_measurement(measurement, keys=keys, headers=headers, save_name='all-spectra-baselined', debug=debug)\n",
    "        print(\"    %s saved!\" % ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"SCRIPT COMPLETE!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
